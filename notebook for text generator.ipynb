{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "# Neural Net Preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Neural Net Layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# Neural Net Training\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from pickle import load\n",
    "import re\n",
    "import sklearn.utils \n",
    "import math\n",
    "\n",
    "\n",
    "# --- Clean up the tweet strings --- \n",
    "def regex_to_pattern_objects(regex_list):\n",
    "    #regex_list = array of strings to be interpreted as regex\n",
    "    pattern_objs = []\n",
    "    for regex in regex_list:\n",
    "        pattern_objs.append(re.compile(regex)) \n",
    "    return pattern_objs \n",
    "\n",
    "def remove_regex(tweet, *bad_patterns):\n",
    "    #tweet = string\n",
    "    #bad_patterns = a list of pattern objects to remove\n",
    "    for pattern in bad_patterns:\n",
    "        tweet = re.sub(pattern, \"\", tweet)\n",
    "    return tweet\n",
    "        \n",
    "def to_lowercase(tweet): #is this necessary lol\n",
    "    return tweet.lower()\n",
    "\n",
    "#TODO: modify the regex list if needed\n",
    "regex_list = ['\\n', 'RT', '&amp', '&#\\d*;', '@\\S*:', '@\\S*', '!+', '\"+', 'https?:\\/\\/t\\.co\\/\\w*', '#', '&\\S*;']\n",
    "pattern_list = regex_to_pattern_objects(regex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "train_df = pd.read_csv('labeled_data.csv')\n",
    "train_df[\"tweet\"] = train_df[\"tweet\"].apply(remove_regex, args = (pattern_list))\n",
    "train_df[\"tweet\"] = train_df[\"tweet\"].apply(to_lowercase)\n",
    "hate_speech = train_df[train_df['class'] == 0][\"tweet\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85                                            queer gaywad\n",
       "89         alsarabsss hes a beaner smh you can tell hes...\n",
       "110        you're fucking gay, blacklisted hoe holding ...\n",
       "184       lmfaoooo i hate black people  this is why the...\n",
       "202                             at least i'm not a nigger \n",
       "                               ...                        \n",
       "24576                  this guy is the biggest faggot omfg\n",
       "24685    which one of these names is more offensive kik...\n",
       "24751           you a pussy ass nigga and i know it nigga.\n",
       "24776                                   you're all niggers\n",
       "24777    you're such a retard i hope you get type 2 dia...\n",
       "Name: tweet, Length: 1430, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98, 1386], [1387, 429, 1, 230, 127, 2, 63, 156, 429, 1, 430], [57, 30, 95, 1388, 72, 652, 71, 28, 1389, 528]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_words =5000# Max size of the dictionary\n",
    "tokens = Tokenizer(num_words=max_words)\n",
    "tokens.fit_on_texts(hate_speech.values)\n",
    "sequences = tokens.texts_to_sequences(hate_speech.values)\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the document:  3686\n"
     ]
    }
   ],
   "source": [
    "words = [item for sublist in sequences for item in sublist]\n",
    "num_words = len(tokens.word_index)\n",
    "print('Number of words in the document: ', num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_len = 10\n",
    "pred_len = 1\n",
    "train_len = sentence_len - pred_len\n",
    "seq = []\n",
    "# Sliding window to generate train data\n",
    "for i in range(len(words)-sentence_len):\n",
    "    seq.append(words[i:i+sentence_len])\n",
    "# Reverse dictionary to decode tokenized sequences back to words\n",
    "reverse_word_map = dict(map(reversed, tokens.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17946 17946\n"
     ]
    }
   ],
   "source": [
    "trainX = []\n",
    "trainy = []\n",
    "for i in seq:\n",
    "    trainX.append(i[:train_len])\n",
    "    trainy.append(i[-1])\n",
    "print(len(trainX),len(trainy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3686"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 9, 50)             184350    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 9, 100)            60400     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3684)              372084    \n",
      "=================================================================\n",
      "Total params: 707,334\n",
      "Trainable params: 707,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential([\n",
    "    Embedding(num_words+1, 50, input_length=train_len),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(num_words-2, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 7.1487 - accuracy: 0.0261\n",
      "Epoch 00001: loss improved from inf to 7.14863, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 7.1486 - accuracy: 0.0261\n",
      "Epoch 2/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 6.7127 - accuracy: 0.0304 ETA: 0s - loss: 6.7132 - accuracy: 0.03\n",
      "Epoch 00002: loss improved from 7.14863 to 6.71247, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 6.7125 - accuracy: 0.0303\n",
      "Epoch 3/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 6.6662 - accuracy: 0.0297\n",
      "Epoch 00003: loss improved from 6.71247 to 6.66649, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 6.6665 - accuracy: 0.0296\n",
      "Epoch 4/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 6.6319 - accuracy: 0.0307 ETA: 0s - loss: 6.6219 - ac\n",
      "Epoch 00004: loss improved from 6.66649 to 6.63310, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 6.6331 - accuracy: 0.0307\n",
      "Epoch 5/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 6.5896 - accuracy: 0.0301\n",
      "Epoch 00005: loss improved from 6.63310 to 6.58860, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 6.5886 - accuracy: 0.0302\n",
      "Epoch 6/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 6.5122 - accuracy: 0.0308\n",
      "Epoch 00006: loss improved from 6.58860 to 6.51183, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 6.5118 - accuracy: 0.0308\n",
      "Epoch 7/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 6.4231 - accuracy: 0.0302\n",
      "Epoch 00007: loss improved from 6.51183 to 6.42149, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 6.4215 - accuracy: 0.0301\n",
      "Epoch 8/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 6.3196 - accuracy: 0.0320\n",
      "Epoch 00008: loss improved from 6.42149 to 6.31962, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 6.3196 - accuracy: 0.0320\n",
      "Epoch 9/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.2039 - accuracy: 0.0356\n",
      "Epoch 00009: loss improved from 6.31962 to 6.20392, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 6.2039 - accuracy: 0.0356\n",
      "Epoch 10/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 6.0927 - accuracy: 0.0373\n",
      "Epoch 00010: loss improved from 6.20392 to 6.09270, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 6.0927 - accuracy: 0.0373\n",
      "Epoch 11/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.9916 - accuracy: 0.0411\n",
      "Epoch 00011: loss improved from 6.09270 to 5.99157, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 5.9916 - accuracy: 0.0411\n",
      "Epoch 12/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.8939 - accuracy: 0.0422\n",
      "Epoch 00012: loss improved from 5.99157 to 5.89390, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 5.8939 - accuracy: 0.0422\n",
      "Epoch 13/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 5.8100 - accuracy: 0.0433\n",
      "Epoch 00013: loss improved from 5.89390 to 5.80954, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 5.8095 - accuracy: 0.0434\n",
      "Epoch 14/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 5.7109 - accuracy: 0.0465\n",
      "Epoch 00014: loss improved from 5.80954 to 5.71191, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 5.7119 - accuracy: 0.0464\n",
      "Epoch 15/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 5.6156 - accuracy: 0.0482\n",
      "Epoch 00015: loss improved from 5.71191 to 5.61668, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 5.6167 - accuracy: 0.0481\n",
      "Epoch 16/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.5181 - accuracy: 0.0503\n",
      "Epoch 00016: loss improved from 5.61668 to 5.51807, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 5.5181 - accuracy: 0.0503\n",
      "Epoch 17/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 5.4073 - accuracy: 0.0527\n",
      "Epoch 00017: loss improved from 5.51807 to 5.40737, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 5.4074 - accuracy: 0.0528\n",
      "Epoch 18/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 5.2855 - accuracy: 0.0556\n",
      "Epoch 00018: loss improved from 5.40737 to 5.28547, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 5.2855 - accuracy: 0.0555\n",
      "Epoch 19/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 5.1685 - accuracy: 0.0620\n",
      "Epoch 00019: loss improved from 5.28547 to 5.16832, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 5.1683 - accuracy: 0.0620\n",
      "Epoch 20/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.0574 - accuracy: 0.0627\n",
      "Epoch 00020: loss improved from 5.16832 to 5.05741, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 5.0574 - accuracy: 0.0627\n",
      "Epoch 21/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 4.9331 - accuracy: 0.0689\n",
      "Epoch 00021: loss improved from 5.05741 to 4.93071, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 4.9307 - accuracy: 0.0691\n",
      "Epoch 22/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 4.8020 - accuracy: 0.0749\n",
      "Epoch 00022: loss improved from 4.93071 to 4.80204, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 4.8020 - accuracy: 0.0751\n",
      "Epoch 23/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.6787 - accuracy: 0.0802\n",
      "Epoch 00023: loss improved from 4.80204 to 4.67867, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 4.6787 - accuracy: 0.0802\n",
      "Epoch 24/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 4.5507 - accuracy: 0.0862\n",
      "Epoch 00024: loss improved from 4.67867 to 4.55292, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 4.5529 - accuracy: 0.0861\n",
      "Epoch 25/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 4.4269 - accuracy: 0.0963\n",
      "Epoch 00025: loss improved from 4.55292 to 4.42696, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 4.4270 - accuracy: 0.0963\n",
      "Epoch 26/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 4.2889 - accuracy: 0.1080\n",
      "Epoch 00026: loss improved from 4.42696 to 4.29018, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 4.2902 - accuracy: 0.1076\n",
      "Epoch 27/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 4.1563 - accuracy: 0.1224 ETA: 0s - loss:\n",
      "Epoch 00027: loss improved from 4.29018 to 4.15849, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 4.1585 - accuracy: 0.1220\n",
      "Epoch 28/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.0651 - accuracy: 0.1351\n",
      "Epoch 00028: loss improved from 4.15849 to 4.06511, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 4.0651 - accuracy: 0.1351\n",
      "Epoch 29/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.9225 - accuracy: 0.1533\n",
      "Epoch 00029: loss improved from 4.06511 to 3.92249, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 3.9225 - accuracy: 0.1533\n",
      "Epoch 30/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 3.8021 - accuracy: 0.1706 ETA: 0s - loss: 3.7895 - accuracy\n",
      "Epoch 00030: loss improved from 3.92249 to 3.80265, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 3.8027 - accuracy: 0.1706\n",
      "Epoch 31/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 3.6861 - accuracy: 0.1935\n",
      "Epoch 00031: loss improved from 3.80265 to 3.68691, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 3.6869 - accuracy: 0.1930\n",
      "Epoch 32/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 3.5623 - accuracy: 0.2105\n",
      "Epoch 00032: loss improved from 3.68691 to 3.56436, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 3.5644 - accuracy: 0.2099\n",
      "Epoch 33/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 3.4515 - accuracy: 0.2271\n",
      "Epoch 00033: loss improved from 3.56436 to 3.45259, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 3.4526 - accuracy: 0.2268\n",
      "Epoch 34/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 3.3445 - accuracy: 0.2479\n",
      "Epoch 00034: loss improved from 3.45259 to 3.34543, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 3.3454 - accuracy: 0.2471\n",
      "Epoch 35/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 3.2359 - accuracy: 0.2693\n",
      "Epoch 00035: loss improved from 3.34543 to 3.23676, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 3.2368 - accuracy: 0.2691\n",
      "Epoch 36/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.1484 - accuracy: 0.2785\n",
      "Epoch 00036: loss improved from 3.23676 to 3.14835, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 3.1484 - accuracy: 0.2785\n",
      "Epoch 37/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 3.0447 - accuracy: 0.3018\n",
      "Epoch 00037: loss improved from 3.14835 to 3.04730, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 3.0473 - accuracy: 0.3010\n",
      "Epoch 38/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.9369 - accuracy: 0.3210\n",
      "Epoch 00038: loss improved from 3.04730 to 2.93690, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 2.9369 - accuracy: 0.3210\n",
      "Epoch 39/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 2.8421 - accuracy: 0.3395\n",
      "Epoch 00039: loss improved from 2.93690 to 2.84449, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 2.8445 - accuracy: 0.3387\n",
      "Epoch 40/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7459 - accuracy: 0.3556\n",
      "Epoch 00040: loss improved from 2.84449 to 2.74594, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 2.7459 - accuracy: 0.3556\n",
      "Epoch 41/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.6663 - accuracy: 0.3764\n",
      "Epoch 00041: loss improved from 2.74594 to 2.66629, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 2.6663 - accuracy: 0.3764\n",
      "Epoch 42/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 2.5834 - accuracy: 0.3928\n",
      "Epoch 00042: loss improved from 2.66629 to 2.58688, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 2.5869 - accuracy: 0.3923\n",
      "Epoch 43/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 2.5004 - accuracy: 0.4062\n",
      "Epoch 00043: loss improved from 2.58688 to 2.50202, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 2.5020 - accuracy: 0.4061\n",
      "Epoch 44/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 2.4493 - accuracy: 0.4169\n",
      "Epoch 00044: loss improved from 2.50202 to 2.44952, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 2.4495 - accuracy: 0.4168\n",
      "Epoch 45/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 2.3815 - accuracy: 0.4320\n",
      "Epoch 00045: loss improved from 2.44952 to 2.38162, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 2.3816 - accuracy: 0.4320\n",
      "Epoch 46/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.3112 - accuracy: 0.4456\n",
      "Epoch 00046: loss improved from 2.38162 to 2.31121, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 2.3112 - accuracy: 0.4456\n",
      "Epoch 47/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 2.2299 - accuracy: 0.4591\n",
      "Epoch 00047: loss improved from 2.31121 to 2.23105, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 2.2310 - accuracy: 0.4589\n",
      "Epoch 48/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.1673 - accuracy: 0.4775\n",
      "Epoch 00048: loss improved from 2.23105 to 2.16727, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 2.1673 - accuracy: 0.4775\n",
      "Epoch 49/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 2.1098 - accuracy: 0.4898\n",
      "Epoch 00049: loss improved from 2.16727 to 2.10782, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 2.1078 - accuracy: 0.4903\n",
      "Epoch 50/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 2.0430 - accuracy: 0.4998\n",
      "Epoch 00050: loss improved from 2.10782 to 2.04262, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 29ms/step - loss: 2.0426 - accuracy: 0.4999\n",
      "Epoch 51/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9744 - accuracy: 0.5202\n",
      "Epoch 00051: loss improved from 2.04262 to 1.97436, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 1.9744 - accuracy: 0.5202\n",
      "Epoch 52/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 1.9102 - accuracy: 0.5338\n",
      "Epoch 00052: loss improved from 1.97436 to 1.91068, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 1.9107 - accuracy: 0.5338\n",
      "Epoch 53/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 1.8643 - accuracy: 0.5441\n",
      "Epoch 00053: loss improved from 1.91068 to 1.86411, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 1.8641 - accuracy: 0.5446\n",
      "Epoch 54/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.8144 - accuracy: 0.5534\n",
      "Epoch 00054: loss improved from 1.86411 to 1.81440, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 1.8144 - accuracy: 0.5534\n",
      "Epoch 55/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 1.7638 - accuracy: 0.5648\n",
      "Epoch 00055: loss improved from 1.81440 to 1.76379, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 1.7638 - accuracy: 0.5647\n",
      "Epoch 56/60\n",
      "140/141 [============================>.] - ETA: 0s - loss: 1.7331 - accuracy: 0.5741\n",
      "Epoch 00056: loss improved from 1.76379 to 1.73374, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 27ms/step - loss: 1.7337 - accuracy: 0.5738\n",
      "Epoch 57/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 1.6811 - accuracy: 0.5830\n",
      "Epoch 00057: loss improved from 1.73374 to 1.67897, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 1.6790 - accuracy: 0.5832\n",
      "Epoch 58/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 1.6351 - accuracy: 0.5910\n",
      "Epoch 00058: loss improved from 1.67897 to 1.63768, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 28ms/step - loss: 1.6377 - accuracy: 0.5905\n",
      "Epoch 59/60\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.5871 - accuracy: 0.6058 E\n",
      "Epoch 00059: loss improved from 1.63768 to 1.58707, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 26ms/step - loss: 1.5871 - accuracy: 0.6058\n",
      "Epoch 60/60\n",
      "139/141 [============================>.] - ETA: 0s - loss: 1.5510 - accuracy: 0.6128\n",
      "Epoch 00060: loss improved from 1.58707 to 1.55084, saving model to .\\hate_speech.hdf5\n",
      "141/141 [==============================] - 4s 25ms/step - loss: 1.5508 - accuracy: 0.6131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train model with checkpoints\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "filepath = \"./hate_speech.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(np.asarray(trainX),\n",
    "         pd.get_dummies(np.asarray(trainy)),\n",
    "         epochs = 60,\n",
    "         batch_size = 128,\n",
    "         callbacks = callbacks_list,\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_weights('hate_speech.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hate(model,text,length):\n",
    "\n",
    "    # Tokenize the input string\n",
    "    passing_tokens = tokens.texts_to_sequences([text])\n",
    "    length = length+len(passing_tokens[0])\n",
    "    # If sentence is not as long as the desired sentence length, we need to 'pad sequence' so that\n",
    "    # the array input shape is correct going into our LSTM. the `pad_sequences` function adds \n",
    "    # zeroes to the left side of our sequence until it becomes 19 long, the number of input features.\n",
    "    while len(passing_tokens[0]) < length:\n",
    "        padded_sentence = pad_sequences(passing_tokens[-19:],maxlen=19)\n",
    "        op = model.predict(np.asarray(padded_sentence).reshape(1,-1))\n",
    "        passing_tokens[0].append(op.argmax()+1)\n",
    "        \n",
    "    return \" \".join(map(lambda x : reverse_word_map[x],passing_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85                                            queer gaywad\n",
       "89         alsarabsss hes a beaner smh you can tell hes...\n",
       "110        you're fucking gay, blacklisted hoe holding ...\n",
       "184       lmfaoooo i hate black people  this is why the...\n",
       "202                             at least i'm not a nigger \n",
       "                               ...                        \n",
       "24576                  this guy is the biggest faggot omfg\n",
       "24685    which one of these names is more offensive kik...\n",
       "24751           you a pussy ass nigga and i know it nigga.\n",
       "24776                                   you're all niggers\n",
       "24777    you're such a retard i hope you get type 2 dia...\n",
       "Name: tweet, Length: 1430, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input Tensor(\"embedding_4_input:0\", shape=(None, 9), dtype=float32), but it was called on an input with incompatible shape (None, 19).\n",
      "New hate speech:  he's white\n",
      "New hate speech:  he's he's a faggot faggot if he stupid bitch don't bitch\n",
      "New hate speech:  faggot bitch he's a faggot a hoe u don't bitch\n",
      "New hate speech:  he's he's a faggot for the school im was trash me trash trash\n",
      "New hate speech:  when he's trash trash trash queer\n",
      "New hate speech:  is a faggot bitch he pussy if the faggot is im you say it your can unfollow he retarded\n",
      "New hate speech:  fag this trash and trash if you look this a faggot and because he trash if he give you\n",
      "New hate speech:  niggas don't bitch he's if the\n",
      "New hate speech:  y was the faggot pussy sit it as the\n",
      "New hate speech:  bitch you can and because a hoes and you can can fuckin to fuckin feminist a\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    test_words = hate_speech.iloc[i].split()\n",
    "    test_string = hate_speech.iloc[i]\n",
    "    new_speech = generate_hate(model,test_string,len(test_words))\n",
    "    new_words = new_speech.split()\n",
    "    print('New hate speech: ',' '.join([j for j in new_words[len(test_words):]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference - 'Simple Text Generation' https://towardsdatascience.com/simple-text-generation-d1c93f43f340"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
